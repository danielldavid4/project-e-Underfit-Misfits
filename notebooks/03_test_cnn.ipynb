{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcec3dd-4337-4192-bb77-be81af7a8ce7",
   "metadata": {},
   "source": [
    "# Project E Simple Object Tracking - 03_Test_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40db8e-e023-478b-941c-ed96d10b7a20",
   "metadata": {},
   "source": [
    "# Project E – 03_Test_CNN\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads the trained CNN model (`simple_cnn_class_and_bbox.h5`).\n",
    "2. Rebuilds the annotated subset of the training data using:\n",
    "   - `training_data_projectE.npy` (video clips)\n",
    "   - `training_labels_projectE.npy` (one-hot labels)\n",
    "   - the provided CSV bounding-box annotations.\n",
    "3. Computes **the same metrics used in training** on this annotated subset:\n",
    "   - total loss\n",
    "   - classification loss and classification accuracy\n",
    "   - bounding-box loss\n",
    "   - bounding-box MSE\n",
    "   - average Intersection-over-Union (IoU) over correctly classified frames\n",
    "4. Prompts the user to select the **blind test `.npy` file**, then:\n",
    "   - runs the trained model on all blind clips,\n",
    "   - outputs a predicted **class label** and **bounding box** for every frame\n",
    "     of every test video, and\n",
    "   - saves these predictions for the instructor to evaluate IoU on the held-out\n",
    "     “easy” blind test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68b22a03-7964-4994-bc1b-db15b4adb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0c21a4a-1221-43d9-a8a6-c440d7584bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base dir   : C:\\Users\\Daniel\\project-e-Underfit-Misfits\n",
      "Data dir   : C:\\Users\\Daniel\\project-e-Underfit-Misfits\\data\n",
      "Models dir : C:\\Users\\Daniel\\project-e-Underfit-Misfits\\models\n",
      "CSV root   : D:\\Documents\\Fundamentals of Machine Learning\\Final_Project_csv\n"
     ]
    }
   ],
   "source": [
    "# Root of your repo\n",
    "base_dir = r\"C:\\Users\\Daniel\\project-e-Underfit-Misfits\"\n",
    "\n",
    "data_dir   = os.path.join(base_dir, \"data\")\n",
    "models_dir = os.path.join(base_dir, \"models\")\n",
    "\n",
    "# Folder where your CSV annotations are stored\n",
    "csv_root   = r\"D:\\Documents\\Fundamentals of Machine Learning\\Final_Project_csv\"\n",
    "\n",
    "print(\"Base dir   :\", base_dir)\n",
    "print(\"Data dir   :\", data_dir)\n",
    "print(\"Models dir :\", models_dir)\n",
    "print(\"CSV root   :\", csv_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10b7e142-ea86-45c6-affd-a7e1e427ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: C:\\Users\\Daniel\\project-e-Underfit-Misfits\\models\\simple_cnn_class_and_bbox.h5\n",
      "Model re-compiled for evaluation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_cnn_class_and_bbox\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"simple_cnn_class_and_bbox\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)               </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                       │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ max_pooling2d              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)             │                        │                │                         │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ max_pooling2d_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)             │                        │                │                         │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,128</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ class (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bbox (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└────────────────────────────┴────────────────────────┴────────────────┴─────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                       │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m448\u001b[0m │ image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ max_pooling2d              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)             │                        │                │                         │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m4,640\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ max_pooling2d_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)             │                        │                │                         │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │      \u001b[38;5;34m2,560,128\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ class (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m645\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├────────────────────────────┼────────────────────────┼────────────────┼─────────────────────────┤\n",
       "│ bbox (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m516\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└────────────────────────────┴────────────────────────┴────────────────┴─────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,566,377</span> (9.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,566,377\u001b[0m (9.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,566,377</span> (9.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,566,377\u001b[0m (9.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = os.path.join(models_dir, \"simple_cnn_class_and_bbox.h5\")\n",
    "\n",
    "# Load WITHOUT compiling\n",
    "model = keras.models.load_model(model_path, compile=False)\n",
    "print(\"Loaded model from:\", model_path)\n",
    "\n",
    "# Re-compile for evaluation (same structure as training)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss={\n",
    "        \"class\": \"sparse_categorical_crossentropy\",\n",
    "        \"bbox\": keras.losses.Huber(),\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"class\": 1.0,\n",
    "        \"bbox\": 5.0,\n",
    "    },\n",
    "    metrics={\n",
    "        \"class\": [\"accuracy\"],\n",
    "        \"bbox\": [\"mse\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Model re-compiled for evaluation.\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3256a44-60d9-46b3-8fcb-8b2618c1f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frame_dataset(data_npy_path, labels_npy_path, csv_root, num_frames=15):\n",
    "    # Load clips and one-hot labels\n",
    "    data_training   = np.load(data_npy_path)                 # (488, 15, 100, 100, 3)\n",
    "    labels_training = np.load(labels_npy_path, allow_pickle=True)  # (488, 15, 5)\n",
    "\n",
    "    num_clips_all, nf, H, W, C = data_training.shape\n",
    "    assert nf == num_frames, f\"Expected {num_frames} frames per clip, got {nf}\"\n",
    "\n",
    "    # Get CSV files (one per annotated clip)\n",
    "    csv_files = sorted(glob.glob(os.path.join(csv_root, \"*.csv\")))\n",
    "    num_clips_annotated = len(csv_files)\n",
    "    print(\"Number of annotated clips (CSV files):\", num_clips_annotated)\n",
    "\n",
    "    # Use only annotated clips from the .npy arrays\n",
    "    data_used   = data_training[:num_clips_annotated]           # (N, 15, 100,100,3)\n",
    "    labels_used = labels_training[:num_clips_annotated]         # (N, 15, 5)\n",
    "\n",
    "    # Build per-clip bounding boxes in normalized [0,1] coordinates\n",
    "    bboxes_per_clip = []\n",
    "\n",
    "    for csv_path in csv_files:\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Resample or pad to exactly num_frames rows\n",
    "        if len(df) > num_frames:\n",
    "            idx = np.linspace(0, len(df) - 1, num_frames).astype(int)\n",
    "            df = df.iloc[idx].reset_index(drop=True)\n",
    "        elif len(df) < num_frames:\n",
    "            repeat_count = num_frames - len(df)\n",
    "            last_row = df.iloc[[-1]].copy()\n",
    "            df = pd.concat([df] + [last_row] * repeat_count, ignore_index=True)\n",
    "\n",
    "        assert len(df) == num_frames, f\"Unexpected #frames in {csv_path}: {len(df)}\"\n",
    "\n",
    "        x  = df[\"bbox_x\"].values.astype(\"float32\")\n",
    "        y  = df[\"bbox_y\"].values.astype(\"float32\")\n",
    "        bw = df[\"bbox_width\"].values.astype(\"float32\")\n",
    "        bh = df[\"bbox_height\"].values.astype(\"float32\")\n",
    "\n",
    "        img_w = df[\"image_width\"].values.astype(\"float32\")\n",
    "        img_h = df[\"image_height\"].values.astype(\"float32\")\n",
    "\n",
    "        x_min = x / img_w\n",
    "        y_min = y / img_h\n",
    "        x_max = (x + bw) / img_w\n",
    "        y_max = (y + bh) / img_h\n",
    "\n",
    "        boxes = np.stack([x_min, y_min, x_max, y_max], axis=1)  # (15,4)\n",
    "        bboxes_per_clip.append(boxes)\n",
    "\n",
    "    bboxes_training = np.stack(bboxes_per_clip, axis=0)        # (N, 15, 4)\n",
    "\n",
    "    # Flatten clips → frames\n",
    "    num_clips_annotated = bboxes_training.shape[0]\n",
    "    frames = data_used.reshape(num_clips_annotated * num_frames, H, W, C)\n",
    "    frame_labels_onehot = labels_used.reshape(num_clips_annotated * num_frames, 5)\n",
    "    frame_labels = np.argmax(frame_labels_onehot, axis=1)\n",
    "    frame_bboxes = bboxes_training.reshape(num_clips_annotated * num_frames, 4).astype(\"float32\")\n",
    "\n",
    "    print(\"frames.shape       :\", frames.shape)\n",
    "    print(\"frame_labels.shape :\", frame_labels.shape)\n",
    "    print(\"frame_bboxes.shape :\", frame_bboxes.shape)\n",
    "\n",
    "    return frames, frame_labels, frame_bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec022340-4982-44c4-8c02-2645b63c449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_boxes(boxes_true, boxes_pred):\n",
    "    x1_true, y1_true, x2_true, y2_true = np.split(boxes_true, 4, axis=1)\n",
    "    x1_pred, y1_pred, x2_pred, y2_pred = np.split(boxes_pred, 4, axis=1)\n",
    "\n",
    "    x1_int = np.maximum(x1_true, x1_pred)\n",
    "    y1_int = np.maximum(y1_true, y1_pred)\n",
    "    x2_int = np.minimum(x2_true, x2_pred)\n",
    "    y2_int = np.minimum(y2_true, y2_pred)\n",
    "\n",
    "    inter_w = np.clip(x2_int - x1_int, 0, None)\n",
    "    inter_h = np.clip(y2_int - y1_int, 0, None)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area_true = (x2_true - x1_true) * (y2_true - y1_true)\n",
    "    area_pred = (x2_pred - x1_pred) * (y2_pred - y1_pred)\n",
    "    union_area = area_true + area_pred - inter_area\n",
    "\n",
    "    iou = inter_area / np.clip(union_area, 1e-7, None)\n",
    "    return iou.squeeze()\n",
    "\n",
    "\n",
    "def test(model, X_eval, y_class_eval, y_box_eval):\n",
    "    \"\"\"\n",
    "    Evaluate on annotated frames:\n",
    "\n",
    "      - total loss\n",
    "      - 'class_loss', 'class_accuracy'\n",
    "      - 'bbox_loss', 'bbox_mse'\n",
    "      - average IoU over correctly classified frames\n",
    "    \"\"\"\n",
    "    # Use Keras evaluate to get loss and metrics\n",
    "    results = model.evaluate(\n",
    "        X_eval,\n",
    "        {\"class\": y_class_eval, \"bbox\": y_box_eval},\n",
    "        verbose=0,\n",
    "        return_dict=True\n",
    "    )\n",
    "\n",
    "    print(\"Keras evaluation metrics on annotated frames:\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "    # Compute IoU over correctly classified frames\n",
    "    pred_class_probs, pred_bboxes = model.predict(X_eval, verbose=0)\n",
    "    pred_class_labels = np.argmax(pred_class_probs, axis=1)\n",
    "\n",
    "    correct_mask = (pred_class_labels == y_class_eval)\n",
    "    num_correct = correct_mask.sum()\n",
    "    total = len(y_class_eval)\n",
    "    acc_pred = num_correct / total\n",
    "\n",
    "    print(f\"\\nFrame-level classification accuracy from predictions: {acc_pred:.3f} ({num_correct}/{total})\")\n",
    "\n",
    "    if num_correct > 0:\n",
    "        true_boxes = y_box_eval[correct_mask]\n",
    "        pred_boxes = pred_bboxes[correct_mask]\n",
    "        ious = iou_boxes(true_boxes, pred_boxes)\n",
    "        mean_iou = ious.mean()\n",
    "        print(f\"Average IoU over correctly classified frames: {mean_iou:.3f}\")\n",
    "    else:\n",
    "        mean_iou = 0.0\n",
    "        print(\"No correctly classified frames; IoU undefined.\")\n",
    "\n",
    "    return results, acc_pred, mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5dc4f3a-6ef3-4c2f-9719-a03432839a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated clips (CSV files): 100\n",
      "frames.shape       : (1500, 100, 100, 3)\n",
      "frame_labels.shape : (1500,)\n",
      "frame_bboxes.shape : (1500, 4)\n",
      "Keras evaluation metrics on annotated frames:\n",
      "  bbox_loss: 0.0050\n",
      "  bbox_mse: 0.0100\n",
      "  class_accuracy: 0.9673\n",
      "  class_loss: 0.1484\n",
      "  loss: 0.1724\n",
      "\n",
      "Frame-level classification accuracy from predictions: 0.967 (1451/1500)\n",
      "Average IoU over correctly classified frames: 0.504\n"
     ]
    }
   ],
   "source": [
    "data_npy_path   = os.path.join(data_dir, \"training_data_projectE.npy\")\n",
    "labels_npy_path = os.path.join(data_dir, \"training_labels_projectE.npy\")\n",
    "\n",
    "frames, frame_labels, frame_bboxes = build_frame_dataset(\n",
    "    data_npy_path,\n",
    "    labels_npy_path,\n",
    "    csv_root,\n",
    "    num_frames=15\n",
    ")\n",
    "\n",
    "# Normalize images\n",
    "X_eval = frames.astype(\"float32\") / 255.0\n",
    "y_class_eval = frame_labels\n",
    "y_box_eval   = frame_bboxes\n",
    "\n",
    "results_dict, acc_from_pred, mean_iou = test(model, X_eval, y_class_eval, y_box_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70e988-4245-40aa-bd20-a761bb5f06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Provide Blind Test File Path (edit this line only) ===\n",
    "\n",
    "# TODO: change this path to wherever the blind .npy file is located\n",
    "blind_test_path = r\"C:\\Users\\Daniel\\Downloads\\easy_blind_test.npy\"\n",
    "\n",
    "print(\"Using blind test file:\")\n",
    "print(blind_test_path)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    blind_test_data = np.load(blind_test_path)\n",
    "    print(\"Blind test shape:\", blind_test_data.shape)\n",
    "except Exception as e:\n",
    "    print(\"ERROR loading file:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e1e2e-de0f-44f9-9727-c83eef21f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_blind_set(model, blind_test_path, num_frames=15, save_prefix=\"blind_test\"):\n",
    "    # 1. Load blind test clips\n",
    "    clips = np.load(blind_test_path)   # expected: (num_clips, 15, 100, 100, 3)\n",
    "    num_clips, nf, H, W, C = clips.shape\n",
    "    assert nf == num_frames, f\"Expected {num_frames} frames, got {nf}\"\n",
    "    print(\"Blind clips shape:\", clips.shape)\n",
    "\n",
    "    # 2. Normalize and flatten to frames\n",
    "    clips_norm = clips.astype(\"float32\") / 255.0\n",
    "    frames = clips_norm.reshape(num_clips * num_frames, H, W, C)\n",
    "\n",
    "    # 3. Predict for every frame\n",
    "    pred_class_probs, pred_bboxes = model.predict(frames, verbose=1)\n",
    "    pred_classes = np.argmax(pred_class_probs, axis=1)\n",
    "\n",
    "    # 4. Reshape back to per-clip, per-frame structure\n",
    "    pred_classes = pred_classes.reshape(num_clips, num_frames)\n",
    "    pred_bboxes  = pred_bboxes.reshape(num_clips, num_frames, 4)\n",
    "\n",
    "    print(\"Predicted class array shape:\", pred_classes.shape)\n",
    "    print(\"Predicted bbox  array shape:\", pred_bboxes.shape)\n",
    "\n",
    "    # 5. Save predictions so the instructor can compute IoU on the blind set\n",
    "    np.save(f\"{save_prefix}_classes.npy\", pred_classes)\n",
    "    np.save(f\"{save_prefix}_bboxes.npy\", pred_bboxes)\n",
    "    print(f\"Saved {save_prefix}_classes.npy and {save_prefix}_bboxes.npy\")\n",
    "\n",
    "    return pred_classes, pred_bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8b21f-41da-4450-85fb-8a9cde56fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes_blind, pred_bboxes_blind = predict_on_blind_set(\n",
    "    model,\n",
    "    blind_test_path,\n",
    "    num_frames=15,\n",
    "    save_prefix=\"easy_blind_test\"   # or any name you like\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fa129-421c-4fe9-af0d-14ec05a3eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
